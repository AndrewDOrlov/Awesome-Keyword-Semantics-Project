## Проект по извлечению ключевых слов из текста и нахождения семантических связей

**Цель:** разработка системы, выделяющей ключевые слова (n-граммы) в тексте публикации и сопоставляющая их со словами в заголовках и тегах с точки зрения семантического сходства.

**Перспективы использования** – выявление ошибочно использованных, повторяющихся и пересекающихся тегов, выявления тематического несоответствия заголовков и текстов публикаций.

**Перспективы дальнейшей разработки** – визуализация и анализ облака тегов для уменьшения количества тегов с целью облегчения пользовательской навигации. Поиск дубликатов тегов с помощью средств NER.

**Поддерживаемые языки:** русский.

**Уточнение цели:** информационные ресурсы в интернете часто сопровождают свои публикации тегами для упрощения поисковых задач. В качестве примеров предлагается рассмотреть сайты [SecurityLab.ru](https://www.securitylab.ru/) и [ICT.Moscow](https://ict.moscow/). Все материалы сайтов открыты для импользования.

В работе с публикациями выявляются такие ошибки, как употребление тегов, несоответствующих теме текста, а также наличие излишних и повторяющихся тегов. Примеры таких ошибок представлены в файле EXAMPLE.md. Проблема неправильных тегов может усугубляться при их автоматической расстановке без импользования средств NLP и затруднять поиск информации на сайте.

Предполагается разработать систему, которая выполнит следующие задачи:
- формирование текстового корпуса публикаций;
- выделение ключевых n-грамм в тексте средствами анализа (TF-IDF, RAKE);
- сравнение выделенных в каждом тексте ключевых n-грамм и содержимого соответствующих тегов и заголовков с помощью векторного представления слов (Rusvectores или Navec);
- сравнительный анализ полученных данных.
- *дополнительно: сравнительная визуализация поля тегов и ключевых слов*

На основании результатов работы системы предполагается выявить случаи неправильного использования тегов и оглавления, а также сформулировать предложения по их корректировке.

>Последующая работа может заключаться в визуализации полученного векторного поля, выявления тегов с максимальным и минимальным смысловым наполнением для уменьшения их количества, заполнения пробелов тегирования, а также тематического анализа интернет-сайта.

>Дополнительной задачей может стать сравнение эффективности моделей Rusvectores и Navec в работе системы.

>Альтернативной задачей может стать выделение в проанализированных текстах слов и выражений, не соответствующих редакционной политике издания (например, коллокаций, характерных для форм первого лица и указаний времени в маркетинговых описаниях или экспрессивно окрашенной лексики в новостных текстах).

**Аналитика:** для решения поставленной задачи – выделения лишней информации в тексте используются программные модели на основе метрики TF-IDF (RAKE), а также модели, создающие векторное представление текстов: Rusvectores или Navec.

**Лингвистический компонент:**
- корпус собирается из новостных материалов сайта [SecurityLab.ru](https://www.securitylab.ru/);
- объем корпуса составляет 2000 текстов. Тексты загружаются с помощью парсера или представляются в формате CSV;
- препроцессинг: удаление пунктуации, лемматизация, токенизация и удаление стоп-слов.

**Входные данные:** файл CSV, содержащий таблицу с текстами, подлежащими анализу (колонки: заголовок, дата, теги, текст).

**Выходные данные:** файл CSV, содержащий таблицу с текстами (колонки: заголовок, дата, n-граммы, оригинальные теги, текст).

**Тестирование:** все публикации [SecurityLab.ru](https://www.securitylab.ru/) сопровождаются тегами и заголовками. Таким образом, пользователь имеет возможность сравнить соответствие оригинальных тегов, заголовков и выделенных системой ключевых слов с помощью векторных моделей. Предполагается выделить для каждого текста пять ключевых n-грамм и исследовать их семантическое сходство с n-граммами в заголовках и тегах публикаций. 

**Использование технических навыков:** сбор собственного корпуса, препроцессинг текстов, создание списков лемм, выделение ключевых слов по метрике TF-IDF, проверка наличия выделенных ключевых слов в соответствующих им заголовках и тегов, оценка их соответствия (с помощью Word2Vec).

**Порядок работы:**
- разработка парсера (загрузчика текстов) или подбор текстов на сайте [SecurityLab.ru](https://www.securitylab.ru/);
- создание текстового корпуса (мероприятия или новости);
- разработка блока выделения ключевых слов текста на основе частотного анализа с помощью библиотек Sklearn или Gensim (метрика TF-IDF);
- разработка блока выделения темы или фильтрующего блока средствами библиотек Gensim и Natasha;
- отладка приложения, разработка интерфейса;
- тестирование приложения в работе с календарем или новостной лентой;
-  *дополнительно: сравнительная визуализация поля тегов и ключевых слов с помощью mathplotter*
-  
### Ссылки 

**извлечение ключевых слов**

[Использование TF IDF для формирования описательных резюме глав посредством извлечения ключевых слов, перевод](https://machinelearningmastery.ru/using-tf-idf-to-form-descriptive-chapter-summaries-via-keyword-extraction-4e6fd857d190/)

[Использование TF IDF для формирования описательных резюме глав посредством извлечения ключевых слов, оригинал](https://towardsdatascience.com/using-tf-idf-to-form-descriptive-chapter-summaries-via-keyword-extraction-4e6fd857d190)

[Описание алгоритмов для выделения ключевых слов: Rake, YAKE!, TextRank](https://vc.ru/newtechaudit/449493-algoritmy-dlya-vydeleniya-klyuchevyh-slov-rake-yake-textrank)

[Создание семантических полей на основе ключевых слов](https://habr.com/ru/company/surfingbird/blog/301922/)

**Векторное представление слов**

[Word2Vec: как работать с векторными представлениями слов](https://neurohive.io/ru/osnovy-data-science/word2vec-vektornye-predstavlenija-slov-dlja-mashinnogo-obuchenija/)

[Обучаем Word2vec: практикум по созданию векторных моделей языка](https://sysblok.ru/knowhow/obuchaem-word2vec-praktikum-po-sozdaniju-vektornyh-modelej-jazyka/)

[Визуализация вложений Word2Vec в Word с помощью t-SNE](https://machinelearningmastery.ru/google-news-and-leo-tolstoy-visualizing-word2vec-word-embeddings-with-t-sne-11558d8bd4d/)

[Проект Natasha](https://github.com/natasha)

[Описание проекта Natasha](https://habr.com/ru/post/516098/)

[Дополнительное описание проекта Natasha](https://habr.com/ru/post/349864/)

[Rusvectores - библиотека вложений](https://rusvectores.org/ru/models/)

[Navec - коллекция предобученных вложений проекта Natasha](https://github.com/natasha/navec)

**извлечение именованных сущностей**

[Описание проекта NRLPK](https://habr.com/ru/post/468141/)
[проект NRLPK](https://github.com/avl33/nrlpk)

**тематическое моделирование**

[Тематическое моделирование средствами BigARTM](https://habr.com/ru/post/334668/)
[Тематическое моделирование новостей с помощью факторного анализа](https://habr.com/ru/post/470618/)
[Тематическое моделирование форума](https://habr.com/ru/company/otus/blog/503398/)

**Дополнительно**

[библиотека проекта Natasha](https://natasha.github.io/corus/)

[открытый датасет Lenta.ru](https://github.com/yutkin/Lenta.Ru-News-Dataset)

[корпус Taiga](https://tatianashavrina.github.io/taiga_site/)

[датасет РИА Новости](https://github.com/RossiyaSegodnya/ria_news_dataset)

[РуСентиЛекс – электронный словарь экспрессивно окрашенной лексики](https://www.labinform.ru/pub/rusentilex/index.htm)

[Using LDA Topic Models as a Classification Model Input](https://towardsdatascience.com/unsupervised-nlp-topic-models-as-a-supervised-learning-input-cf8ee9e5cf28)

[Unsupervised topic model in Python](https://towardsdatascience.com/introduction-to-nlp-part-5a-unsupervised-topic-model-in-python-733f76b3dc2d)

[The Ultimate Guide to Clustering Algorithms and Topic Modeling](https://towardsdatascience.com/the-ultimate-guide-to-clustering-algorithms-and-topic-modeling-3a65129df324)

[Zero-shot Topic Modeling with Deep Learning Using Python Hugging Face](https://medium.com/grabngoinfo/zero-shot-topic-modeling-with-deep-learning-using-python-a895d2d0c773)

[Multilingual Dynamic Topic Model](https://aclanthology.org/R19-1159/)

[Labeled LDA: A supervised topic model for credit attribution in multi-labeled corpora](https://aclanthology.org/D09-1026/)

[Tree-Structured Neural Topic Model](https://aclanthology.org/2020.acl-main.73/)
