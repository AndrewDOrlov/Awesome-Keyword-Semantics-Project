## Проект по расстановке тегов с помощью тематического моделирования корпуса текстов

**Цель:** разработка системы, выполняющей тематическое моделирование корпуса текстов и присваивающей каждому тексту соответствующие ему теги.

**Поддерживаемые языки:** русский.

**Перспективы использования** – автоматическая расстановка тегов публикаций на сайте для облегчения пользовательской навигации с исправлением выявленных ошибок (полное дублирование тегов, наличие излишних тегов, несоответствие тегов и текстов, отсутствие тегов и т.д.). 

**Перспективы дальнейшей разработки** – Выделение двусложных тегов помимо односложных ;выделение из общего облака тегов именованных сущностей (организаций и персон) с помощью средств NER; выявление дублирующихся тегов именованных сущностей; добавление средств обработки текста на английском языке.

**Уточнение цели:** публикации в интернете часто сопровождаются тегами для упрощения поисковых задач. В качестве примеров предлагается рассмотреть сайт [SecurityLab.ru](https://www.securitylab.ru/), посвященный кибербезопасности. Все материалы сайтов открыты для импользования.

В работе с публикациями выявляются такие ошибки, как употребление тегов, несоответствующих теме текста, а также наличие излишних и повторяющихся тегов. Примеры выявленных ошибок представлены в файле EXAMPLE.md. Проблема неправильных тегов может усугубляться при их автоматической расстановке без импользования комплексных средств NLP и затруднять поиск информации на сайте.

Предполагается разработать систему, которая выполнит следующие задачи:
- формирование текстового корпуса публикаций;
- выделение в корпусе текстов тем и относящихся к ним ключевых слов с помощью средств тематического моделирования (LDA);
- добавление к каждому тексту новых тегов из выделенных ключевых слов;
- визуализация полученного облака тегов корпуса соответственно их значениям.

В результате работы системы предполагается выявить и исправить случаи неправильного использования тегов, что облегчит пользовательскую навигацию и создаст представление о содержимом корпуса.

**Аналитика:** для решения поставленной задачи – выделения составляющих корпус тем используется программная реализация латентного разложения Дирихле (LDA). Для оценки работы системы используются метрика оценки topic coherence c_v.

**Лингвистический компонент:**
- корпус собирается из новостных материалов информационного сайта [SecurityLab.ru](https://www.securitylab.ru/), посвященного кибербезопасности;
- объем корпуса составляет 8000 текстов. Тексты загружаются с помощью парсера;
- препроцессинг: удаление пунктуации, токенизация, лемматизация, и удаление стоп-слов.

**Входные данные:** файл CSV, содержащий таблицу с текстами, подлежащими анализу (колонки: ссылка, заголовок, подзаголовок, теги, текст).

**Выходные данные:** файл CSV, содержащий таблицу с текстами (колонки: ссылка, заголовок, подзаголовок, теги, текст, прдобработанный текст, новые теги); Изображение в формате png, сожержащее визуализацию облака ключевых слов-тегов для корпуса.

**Тестирование:** все публикации [SecurityLab.ru](https://www.securitylab.ru/) сопровождаются тегами и заголовками. Таким образом, пользователь имеет возможность сравнить соответствие оригинальных тегов, заголовков, подзаголовков и выделенных системой ключевых слов.

**Использование технических навыков:** сбор корпуса текстов, препроцессинг текстов, создание списков лемм, использование регулярных выражений, использование библиотек BeautifulSoup, Requests, Regex, Pandas, Pymorphy, NLTK, Gensim, Matplotlib.

**Порядок работы:**
- разработка парсера (загрузчика текстов) для сайта [SecurityLab.ru](https://www.securitylab.ru/);
- создание текстового корпуса из новостных публикаций;
- разработка функции тематического моделирования;
- разработка функции грамматической фильтрации средствами библиотеки Spacy;
- разработка функции фильтрации на основе семантического сходства с помощью модели Rusvectores или Navec;
- создание функции визуализации облака ключевых слов с помощью библиотеки mathplotter;
- создание общей функции выделения ключевых слов;
- 
-  *дополнительно: разработка функций выделения ключевых слов с помощью Gensim и KeyBERT;
 
### Ссылки 

**извлечение ключевых слов**

[Описание алгоритмов для выделения ключевых слов: Rake, YAKE!, TextRank](https://vc.ru/newtechaudit/449493-algoritmy-dlya-vydeleniya-klyuchevyh-slov-rake-yake-textrank)

[Пример сравнительного использования алгоритмов Rake и keyBERT, а также грамматическая фильтрация средствами Spacy](https://towardsdatascience.com/keyword-extraction-a-benchmark-of-7-algorithms-in-python-8a905326d93f)

[Библиотека RAKE-nltk](https://pypi.org/project/rake-nltk/)

[Библиотека nlp-rake](https://pypi.org/project/nlp-rake/)

**Векторное представление слов**

[Проект Natasha](https://github.com/natasha)

[Описание проекта Natasha](https://habr.com/ru/post/516098/)

[Дополнительное описание проекта Natasha](https://habr.com/ru/post/349864/)

[Rusvectores - библиотека вложений](https://rusvectores.org/ru/models/)

[Navec - коллекция предобученных вложений проекта Natasha](https://github.com/natasha/navec)

**Визуализация ключевых слов**

[Визуализация вложений Word2Vec в Word с помощью t-SNE](https://machinelearningmastery.ru/google-news-and-leo-tolstoy-visualizing-word2vec-word-embeddings-with-t-sne-11558d8bd4d/)

**извлечение именованных сущностей**

[Описание проекта NRLPK](https://habr.com/ru/post/468141/)
[проект NRLPK](https://github.com/avl33/nrlpk)

**Дополнительно**

[Word2Vec: как работать с векторными представлениями слов](https://neurohive.io/ru/osnovy-data-science/word2vec-vektornye-predstavlenija-slov-dlja-mashinnogo-obuchenija/)

[Обучаем Word2vec: практикум по созданию векторных моделей языка](https://sysblok.ru/knowhow/obuchaem-word2vec-praktikum-po-sozdaniju-vektornyh-modelej-jazyka/)

[библиотека проекта Natasha](https://natasha.github.io/corus/)

[открытый датасет Lenta.ru](https://github.com/yutkin/Lenta.Ru-News-Dataset)

[корпус Taiga](https://tatianashavrina.github.io/taiga_site/)

[датасет РИА Новости](https://github.com/RossiyaSegodnya/ria_news_dataset)
