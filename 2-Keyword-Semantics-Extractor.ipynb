{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79875e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995efcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From RAKE-nltk page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "\n",
    "# Uses stopwords for english from NLTK, and all puntuation characters by\n",
    "# default\n",
    "r = Rake()\n",
    "\n",
    "# Extraction given the text.\n",
    "r.extract_keywords_from_text(<text to process>)\n",
    "\n",
    "# Extraction given the list of strings where each string is a sentence.\n",
    "r.extract_keywords_from_sentences(<list of sentences>)\n",
    "\n",
    "# To get keyword phrases ranked highest to lowest.\n",
    "r.get_ranked_phrases()\n",
    "\n",
    "# To get keyword phrases ranked highest to lowest with scores.\n",
    "r.get_ranked_phrases_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e002a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From vc.ru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from ntlk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stops = list(set(stopwords.words(\"russian\")))\n",
    "\n",
    "r = Rake(stopwords = stops, max words = 3)\n",
    "r.apply(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4523f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From towardsdatascience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rake_extractor(text):\n",
    "    \"\"\"\n",
    "    Uses Rake to extract the top 5 keywords from a text\n",
    "    Arguments: text (str)\n",
    "    Returns: list of keywords (list)\n",
    "    \"\"\"\n",
    "    r = Rake()\n",
    "    r.extract_keywords_from_text(text)\n",
    "    return r.get_ranked_phrases()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2607a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy match function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(keyword):\n",
    "    \"\"\"This function checks if a list of keywords match a certain POS pattern\"\"\"\n",
    "    patterns = [\n",
    "        [{'POS': 'PROPN'}, {'POS': 'VERB'}, {'POS': 'VERB'}],\n",
    "        [{'POS': 'NOUN'}, {'POS': 'VERB'}, {'POS': 'NOUN'}],\n",
    "        [{'POS': 'VERB'}, {'POS': 'NOUN'}],\n",
    "        [{'POS': 'ADJ'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}],  \n",
    "        [{'POS': 'NOUN'}, {'POS': 'VERB'}],\n",
    "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}],\n",
    "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}],\n",
    "        [{'POS': 'ADJ'}, {'POS': 'NOUN'}],\n",
    "        [{'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}],\n",
    "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'ADV'}, {'POS': 'PROPN'}],\n",
    "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'VERB'}],\n",
    "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}],\n",
    "        [{'POS': 'NOUN'}, {'POS': 'NOUN'}],\n",
    "        [{'POS': 'ADJ'}, {'POS': 'PROPN'}],\n",
    "        [{'POS': 'PROPN'}, {'POS': 'ADP'}, {'POS': 'PROPN'}],\n",
    "        [{'POS': 'PROPN'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}],\n",
    "        [{'POS': 'PROPN'}, {'POS': 'VERB'}, {'POS': 'NOUN'}],\n",
    "        [{'POS': 'NOUN'}, {'POS': 'ADP'}, {'POS': 'NOUN'}],\n",
    "        [{'POS': 'PROPN'}, {'POS': 'NOUN'}, {'POS': 'PROPN'}],\n",
    "        [{'POS': 'VERB'}, {'POS': 'ADV'}],\n",
    "        [{'POS': 'PROPN'}, {'POS': 'NOUN'}],\n",
    "        ]\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"pos-matcher\", patterns)\n",
    "    # create spacy object\n",
    "    doc = nlp(keyword)\n",
    "    # iterate through the matches\n",
    "    matches = matcher(doc)\n",
    "    # if matches is not empty, it means that it has found at least a match\n",
    "    if len(matches) > 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e2032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f52971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_from_corpus(extractor, corpus):\n",
    "    \"\"\"This function uses an extractor to retrieve keywords from a list of documents\"\"\"\n",
    "    extractor_name = extractor.__name__.replace(\"_extractor\", \"\")\n",
    "    logging.info(f\"Starting keyword extraction with {extractor_name}\")\n",
    "    corpus_kws = {}\n",
    "    start = time.time()\n",
    "    # logging.info(f\"Timer initiated.\") <-- uncomment this if you want to output start of timer\n",
    "    for idx, text in tqdm(enumerate(corpus), desc=\"Extracting keywords from corpus...\"):\n",
    "        corpus_kws[idx] = extractor(text)\n",
    "    end = time.time()\n",
    "    # logging.info(f\"Timer stopped.\") <-- uncomment this if you want to output end of timer\n",
    "    elapsed = time.strftime(\"%H:%M:%S\", time.gmtime(end - start))\n",
    "    logging.info(f\"Time elapsed: {elapsed}\")\n",
    "    \n",
    "    return {\"algorithm\": extractor.__name__, \n",
    "            \"corpus_kws\": corpus_kws, \n",
    "            \"elapsed_time\": elapsed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfbe3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db486fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # create results dataframe\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"results.csv\", index=False)\n",
    "    logging.info(\"Benchmark finished. Results saved to results.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(corpus, shuffle=True):\n",
    "    \"\"\"This function runs the benchmark for the keyword extraction algorithms\"\"\"\n",
    "    logging.info(\"Starting benchmark...\\n\")\n",
    "    \n",
    "    # Shuffle the corpus\n",
    "    if shuffle:\n",
    "        random.shuffle(corpus)\n",
    "\n",
    "    # extract keywords from corpus\n",
    "    results = []\n",
    "    extractors = [\n",
    "        rake_extractor, \n",
    "        yake_extractor, \n",
    "        topic_rank_extractor, \n",
    "        position_rank_extractor,\n",
    "        single_rank_extractor,\n",
    "        multipartite_rank_extractor,\n",
    "        keybert_extractor,\n",
    "    ]\n",
    "    for extractor in extractors:\n",
    "        result = extract_keywords_from_corpus(extractor, corpus)\n",
    "        results.append(result)\n",
    "\n",
    "    # compute average number of extracted keywords\n",
    "    for result in results:\n",
    "        len_of_kw_list = []\n",
    "        for kws in result[\"corpus_kws\"].values():\n",
    "            len_of_kw_list.append(len(kws))\n",
    "        result[\"avg_keywords_per_document\"] = np.mean(len_of_kw_list)\n",
    "\n",
    "    # match keywords\n",
    "    for result in results:\n",
    "        for idx, kws in result[\"corpus_kws\"].items():\n",
    "            match_results = []\n",
    "            for kw in kws:\n",
    "                match_results.append(match(kw))\n",
    "                result[\"corpus_kws\"][idx] = match_results\n",
    "\n",
    "    # compute average number of matched keywords\n",
    "    for result in results:\n",
    "        len_of_matching_kws_list = []\n",
    "        for idx, kws in result[\"corpus_kws\"].items():\n",
    "            len_of_matching_kws_list.append(len([kw for kw in kws if kw]))\n",
    "        result[\"avg_matched_keywords_per_document\"] = np.mean(len_of_matching_kws_list)\n",
    "        # compute average percentange of matching keywords, round 2 decimals\n",
    "        result[\"avg_percentage_matched_keywords\"] = round(result[\"avg_matched_keywords_per_document\"] / result[\"avg_keywords_per_document\"], 2)\n",
    "        \n",
    "    # create score based on the avg percentage of matched keywords divided by time elapsed (in seconds)\n",
    "    for result in results:\n",
    "        elapsed_seconds = get_sec(result[\"elapsed_time\"]) + 0.1\n",
    "        # weigh the score based on the time elapsed\n",
    "        result[\"performance_score\"] = round(result[\"avg_matched_keywords_per_document\"] / elapsed_seconds, 2)\n",
    "    \n",
    "    # delete corpus_kw\n",
    "    for result in results:\n",
    "        del result[\"corpus_kws\"]\n",
    "\n",
    "    # create results dataframe\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"results.csv\", index=False)\n",
    "    logging.info(\"Benchmark finished. Results saved to results.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad98d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f084a7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (454629916.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf99d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "path = 'data/navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
    "#path = 'data/navec_hudlit_v1_12B_500K_300d_100q.tar' uncomment if wget is used\n",
    "navec = Navec.load(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
